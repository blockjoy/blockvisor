const METADATA = #{
    // A semver version of the babel program, indicating the minimum version of the babel
    // program that a babel script is compatible with.
    min_babel_version: "0.0.9",
    /// Version of Linux kernel to use in VM.
    kernel: "5.10.174-build.1+fc.ufw",
    // A semver version of the blockchain node program.
    node_version: "0.0.1",
    // Name of the blockchain protocol.
    protocol: "{{ protocol }}",
    // Type of the node (validator, beacon, etc).
    node_type: "{{ node_type }}",
    // [optional] Some description of the node.
    description: "{{ protocol }} {{ node_type }}",
    // Blockchain resource requirements.
    requirements: #{
        // Virtual cores to share with VM
        vcpu_count: 1,
        // RAM allocated to VM in MB
        mem_size_mb: 2048,
        // Size of data drive for storing blockchain data (not to be confused with OS drive)
        disk_size_gb: 1,
    },
    // Supported blockchain networks.
    nets: #{
        // Key is the name of blockchain network
        test: #{
            // Url for given blockchain network.
            url: "https://testnet-api.helium.wtf/v1/",
            // Blockchain network type.
            // Allowed values: "dev", "test", "main"
            net_type: "test",
            // [optional] Custom network metadata can also be added.
            // example: beacon_nodes_csv: "http://beacon01.goerli.eth.blockjoy.com,http://beacon02.goerli.eth.blockjoy.com?789",
        },
        main: #{
            url: "https://rpc.ankr.com/eth",
            net_type: "main",
        },
    },
    // Configuration of Babel - agent running inside VM.
    babel_config: #{
        // Path to mount data drive to.
        // Capacity of log buffer (in lines).
        log_buffer_capacity_ln: 1024,
        // Size of swap file created on the node, in MB.
        swap_size_mb: 512,
        // Location of swap file.
        swap_file_location: "/swapfile",
        // Set RAM disks inside VM
        ramdisks: [
            #{
                // Path to mount RAM disk to.
                ram_disk_mount_point: "/mnt/ramdisk",
                // RAM disk size, in MB.
                ram_disk_size_mb: 512,
            },
        ]
    },
    // Node firewall configuration.
    firewall: #{
        // Option to disable firewall at all. Only for debugging purpose - use on your own risk!
        enabled: true,
        // Fallback action for inbound traffic used when packet doesn't match any rule.
        // Allowed values: "allow", "deny", "reject"
        default_in: "deny",
        // Fallback action for outbound traffic used when packet doesn't match any rule.
        // Allowed values: "allow", "deny", "reject"
        default_out: "allow",
        // Set of rules to be applied.
        rules: [
            #{
                // Unique rule name.
                name: "Allowed incoming tcp traffic on port",
                // Action applied on packet that match rule.
                // Allowed values: "allow", "deny", "reject"
                action: "allow",
                // Traffic direction for which rule applies.
                // Allowed values: "out", "in"
                direction: "in",
                // [optional] Protocol - "both" by default.
                // Allowed values: "tcp", "udp", "both"
                protocol: "tcp",
                // [optional] Ip(s) compliant with CIDR notation.
                // ips: "192.167.0.1/24",
                // List of ports. Empty means all.
                ports: [24567], // ufw allow in proto tcp port 24567
            },
            #{
                name: "Allowed incoming udp traffic on ip and port",
                action: "allow",
                direction: "in",
                protocol: "udp",
                ips: "192.168.0.1",
                ports: [24567], // ufw allow in proto udp from 192.168.0.1 port 24567
            },
        ],
    },
};

// You can define some constants to use in the code
const API_HOST = "http://localhost:4467/";
const A_DIR = BLOCKCHAIN_DATA_PATH + "/A/";
const B_DIR = BLOCKCHAIN_DATA_PATH + "/B/";
const NET =  global::METADATA.nets[node_params().NETWORK];

// Helper function to stop all blockchain services (aka entrypoints)
fn stop_blockchain() {
    stop_job("blockchain_service_a");
    stop_job("blockchain_service_b");
}

// Helper function to start all blockchain services (aka entrypoints)
fn start_blockchain(needed) {
    // Start background job with unique name
    start_job("blockchain_service_a", #{
        // Job type
        job_type: #{
            // Sh script body
            run_sh: `/usr/bin/blockchain_service_a start --home=${A_DIR} --chain=${NET.net_type} --rest-server --seeds ${NET.seeds} "$@"`,
        },
        // Job restart policy
        // "never" indicates that this job will never be restarted, whether succeeded or not - appropriate for jobs
        // that can't be simply restarted on failure (e.g. need some manual actions)
        // "on_failure" key means that job is restarted only if `exit_code != 0`
        // "always" key means that job is always restarted - equivalent to entrypoint
        restart: #{
            always: #{
                // if job stay alive given amount of time (in miliseconds) backoff is reset
                backoff_timeout_ms: 60000,
                // base time (in miliseconds) for backof,
                // multiplied by consecutive power of 2 each time
                backoff_base_ms: 1000,
                // [optional] maximum number of retries, or there is no such limit if not set
                // max_retries: 3,
            },
        },
        // [optional] List of job names that this job needs to be finished before start, may be empty
        needs: needed,
    });
    start_job("blockchain_service_b", #{
        job_type: #{
            run_sh: `/usr/bin/blockchain_service_b --chain=${NET.net_type} --datadir=${A_DIR} --snapshots=false`,
        },
        restart: #{
            always: #{
                backoff_timeout_ms: 60000,
                backoff_base_ms: 1000,
            },
        },
        needs: needed,
    });
}

// Function that is called by BV on first node start.
// It takes keys key-value map as argument.
// SHALL be implemented
fn init(keys) {
    // Allowing people to put arbitrary data into sh-commands safely
    let param = sanitize_sh_param(node_params().EXAMPLE_PARAM);

    // Run Sh script on the blockchain VM and return it's result (with default 15s timeout)
    let res = run_sh("echo 'noop template rhai file parametrized with: " + param + "'");
    if res.exit_code != 0  {
        throw res;
    }

    // Logging function like debug, info, warn, error could be used
    info("some important step logged with INFO level");

    try {
        // try built-in download method first, to speedup regular nodes setup
        start_job("download", #{
            job_type: #{
                download: #{
                    // [optional] Maximum number of parallel opened connections.
                    max_connections: 5,
                    // [optional] Maximum number of parallel workers.
                    max_runners: 8,
                },
            },
            restart: #{
                on_failure: #{
                    backoff_timeout_ms: 60000,
                    backoff_base_ms: 1000,
                    max_retries: 5,
                },
            },
        });
    } catch {
        // if it fail (maybe not uploaded yet), try blockchain provided archives (if any), to speed up first sync
        start_job("download", #{
            job_type: #{
                run_sh: `/usr/bin/wget -q -O - ${global::SNAPSHOT_UTIL_URL}`,
            },
            restart: #{
                on_failure: #{
                    backoff_timeout_ms: 60000,
                    backoff_base_ms: 10000,
                    max_retries: 3,
                },
            },
        });
    }
    // start blockchain services once download is finished
    start_blockchain(["download"]);
}

// The address of the node.
// The meaning of this varies from blockchain to blockchain.
// SHALL be implemented
fn address() {
    parse_json(run_jrpc(#{ host: global::API_HOST, method: "peer_addr"}).body).result.peer_addr.to_string()
}

// Returns blockchain application status.
// SHALL be implemented
fn application_status() {
    "broadcasting"
}

// Returns the height of the blockchain (in blocks).
// SHOULD be implemented
fn height() {
    parse_json(run_jrpc(#{ host: global::API_HOST, method: "info_height"}).body).result.height
}

// Returns the block age of the blockchain (in seconds).
// SHOULD be implemented
fn block_age() {
    parse_json(run_jrpc(#{ host: global::API_HOST, method: "info_block_age"}).body).result.block_age
}

// Returns the name of the node.
// The meaning of this varies from blockchain to blockchain.
// SHOULD be implemented
fn name() {
    parse_json(run_jrpc(#{ host: global::API_HOST, method: "info_name"}).body).result.name.to_string()
}

// Returns bool whether this node is in consensus or not.
// SHOULD be implemented
fn consensus() {
    false
}

// Returns blockchain synchronization status.
// SHOULD be implemented
fn sync_status() {
    "synced"
}

// Returns blockchain staking status.
// SHOULD be implemented
fn staking_status() {
    "staking"
}

// Test functions starting with test_ COULD be implemented as part of test harness
// Running `bv node check ID_OR_NAME` will execute all defined test_* functions
// MAY be implemented
fn test_height_value(param) {
    if height() < 0 {
        throw "Invalid node height value: " + height();
    }
}

// Helper function that can be run, to upload blockchain data archive.
fn upload(param) {
    stop_blockchain();
    start_job("upload", #{
        job_type: #{
            upload: #{
                // [optional] List of exclude patterns. Files in `BLOCKCHAIN_DATA_PATH` directory that match any of pattern,
                // won't be taken into account.
                exclude: [
                    "**/something_to_ignore*",
                    ".gitignore",
                    "some_subdir/*.bak",
                ],
                // [optional] Compression to be used on chunks.
                compression: #{
                    ZSTD: 3, // compression level
                },
                // [optional] Maximum number of parallel opened connections.
                max_connections: 4,
                // [optional] Maximum number of parallel workers.
                max_runners: 12,
                // [optional] Number of chunks that blockchain data should be split into.
                // Recommended chunk size is about 1GB. Estimated by BV based on data size, if not provided.
                //number_of_chunks: 700,
                // [optional] Seconds after which presigned urls in generated `UploadManifest` may expire.
                //url_expires_secs: 240000,
                // [optional] Version number for uploaded data. Auto-assigned if not provided.
                //data_version: 3,
            }
        },
        restart: #{
            on_failure: #{
                backoff_timeout_ms: 60000,
                backoff_base_ms: 1000,
                max_retries: 5,
            },
        },
    });
    // start blockchain services again once upload is finished
    start_blockchain(["upload"]);
    "Upload started!"
}
